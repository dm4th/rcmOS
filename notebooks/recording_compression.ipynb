{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image Processing Packages\n",
    "import cv2\n",
    "\n",
    "# OS Screen Capture Pacakges\n",
    "import mss\n",
    "import mss.tools\n",
    "\n",
    "# Concurrency Packages\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Globals\n",
    "DURATION = 10 # Set testing video duration in seconds\n",
    "THRESHOLD = 30 # Threshold for detecting a differencebetween frames in a recording\n",
    "FRAME_RATE = 10 # Set frame rate for recording\n",
    "FRAME_INTERVAL = 1/FRAME_RATE # Set frame interval for recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Recordings & Screenshots Directories\n",
    "if not os.path.exists('./recordings'):\n",
    "    os.makedirs('./recordings')\n",
    "\n",
    "if not os.path.exists('./screenshots'):\n",
    "    os.makedirs('./screenshots')\n",
    "\n",
    "sub_directories = ['initial','compression']\n",
    "\n",
    "for sub_directory in sub_directories:\n",
    "    if not os.path.exists('./recordings/' + sub_directory):\n",
    "        os.makedirs('./recordings/' + sub_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a short function for naming conventions\n",
    "def name_converter(num):\n",
    "    if num == 0:\n",
    "        return 'total'\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'left': -1256, 'top': -1080, 'width': 4480, 'height': 1980}, {'left': 0, 'top': 0, 'width': 1440, 'height': 900}, {'left': -1256, 'top': -1080, 'width': 1920, 'height': 1080}, {'left': 664, 'top': -1080, 'width': 2560, 'height': 1080}]\n"
     ]
    }
   ],
   "source": [
    "# Get connected monitors, their dimensions, total combined dimensions, and take a sample screenshot of each\n",
    "with mss.mss() as sct:\n",
    "    # Get connected monitors\n",
    "    monitors = sct.monitors\n",
    "    print(monitors)\n",
    "\n",
    "    # Take a sample screenshot of each monitor\n",
    "    for i, monitor in enumerate(monitors):\n",
    "        sct_img = sct.grab(monitor)\n",
    "        mss.tools.to_png(sct_img.rgb, sct_img.size, output=f'./screenshots/monitor_{name_converter(i)}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4 character code of codec used to compress the frames\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to screen grab and write frames to an output video file\n",
    "def record_monitor(monitor, output_file):\n",
    "    output_writer = cv2.VideoWriter(output_file, fourcc, FRAME_RATE, (monitor['width'], monitor['height']))\n",
    "    start_time = time.time()\n",
    "    with mss.mss() as sct:\n",
    "        while time.time() - start_time < DURATION:\n",
    "            loop_start = time.time()\n",
    "\n",
    "            # Grab the current frame\n",
    "            sct_img = sct.grab(monitor)\n",
    "\n",
    "            # Convert the frame to a numpy array and then to a cv2 image\n",
    "            frame = np.array(sct_img)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Write the frame to the output file\n",
    "            output_writer.write(frame)\n",
    "\n",
    "            loop_end = time.time()\n",
    "            elapsed_time = loop_end - loop_start\n",
    "            if elapsed_time < FRAME_INTERVAL:\n",
    "                time.sleep(FRAME_INTERVAL - elapsed_time)\n",
    "\n",
    "    output_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the screens\n",
    "# Create VideoWriter object to save the video\n",
    "# Get the recording number\n",
    "recordings_dir = './recordings/initial'\n",
    "recordings_count = int(len(os.listdir(recordings_dir))/len(monitors))\n",
    "\n",
    "# Create a thread to record each monitor\n",
    "threads = []\n",
    "for i, monitor in enumerate(monitors):\n",
    "    output_file = f'{recordings_dir}/monitor_{name_converter(i)}_{recordings_count}.mp4'\n",
    "    thread = threading.Thread(target=record_monitor, args=(monitor, output_file))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "recordings_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Threshold-Based Compression Technique\n",
    "# Calculate the differences between the frames to reduce the size of the video\n",
    "\n",
    "# Using moviepy to edit the videos\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.ffmpeg_reader import FFMPEG_VideoReader\n",
    "\n",
    "# Increase the analyzeduration and probesize options\n",
    "FFMPEG_VideoReader.analyzeduration = 10**8\n",
    "FFMPEG_VideoReader.probesize = 10**8\n",
    "\n",
    "# Function to calculate the difference between two frames\n",
    "def frame_diff(prev_frame, cur_frame, threshold):\n",
    "    return np.mean(np.abs(prev_frame.astype(int) - cur_frame.astype(int))) > threshold\n",
    "\n",
    "# Function to Process a Video\n",
    "def process_video(input_file, output_file, threshold=THRESHOLD):\n",
    "    # Load the video, initialize the start and end times arrays to know places we can cut\n",
    "    video = mp.VideoFileClip(input_file)\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "\n",
    "    # Iterate over the frames in the video, keeping track of the last frame\n",
    "    last_frame = None\n",
    "    for t in video.iter_frames(with_times=True, dtype=int):\n",
    "        time, frame = t\n",
    "\n",
    "        # If this is the first frame, initialize the last frame\n",
    "        if last_frame is not None:\n",
    "            # Check to see if the difference between the current frame and the last frame is above the threshold\n",
    "            if frame_diff(last_frame, frame, threshold):\n",
    "                start_times.append(time)\n",
    "                if len(end_times) > 0:\n",
    "                    end_times[-1] = time\n",
    "            else:\n",
    "                if len(end_times) == 0:\n",
    "                    end_times.append(time)\n",
    "                else:\n",
    "                    end_times[-1] = time\n",
    "\n",
    "        last_frame = frame\n",
    "\n",
    "    if len(start_times) > len(end_times):\n",
    "        end_times.append(video.duration)\n",
    "\n",
    "    # Create a new video with the start and end times\n",
    "    print(f'Start Times: {start_times}')\n",
    "    print(f'End Times: {end_times}')\n",
    "    clips = [video.subclip(start, end) for start, end in zip(start_times, end_times)]\n",
    "    output_video = mp.concatenate_videoclips(clips)\n",
    "    output_video.write_videofile(output_file, codec=\"libx264\")\n",
    "\n",
    "\n",
    "# Function to convert a video without processing it\n",
    "def convert_video(input_file, output_file):\n",
    "    video = mp.VideoFileClip(input_file)\n",
    "    video.write_videofile(output_file, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Times: []\n",
      "End Times: [2.1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# for m in range(len(monitors)):\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m process_video(\n\u001b[1;32m      3\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./recordings/initial/monitor_2_0.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./recordings/compression/monitor_2_0.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m )\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(input_file, output_file, threshold)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEnd Times: \u001b[39m\u001b[39m{\u001b[39;00mend_times\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m clips \u001b[39m=\u001b[39m [video\u001b[39m.\u001b[39msubclip(start, end) \u001b[39mfor\u001b[39;00m start, end \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(start_times, end_times)]\n\u001b[0;32m---> 50\u001b[0m output_video \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mconcatenate_videoclips(clips)\n\u001b[1;32m     51\u001b[0m output_video\u001b[39m.\u001b[39mwrite_videofile(output_file, codec\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlibx264\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/rcmos/lib/python3.11/site-packages/moviepy/video/compositing/concatenate.py:75\u001b[0m, in \u001b[0;36mconcatenate_videoclips\u001b[0;34m(clips, method, transition, bg_color, ismask, padding)\u001b[0m\n\u001b[1;32m     71\u001b[0m tt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcumsum([\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m [c\u001b[39m.\u001b[39mduration \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m clips])\n\u001b[1;32m     73\u001b[0m sizes \u001b[39m=\u001b[39m [v\u001b[39m.\u001b[39msize \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m clips]\n\u001b[0;32m---> 75\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(r[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m r \u001b[39min\u001b[39;49;00m sizes)\n\u001b[1;32m     76\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(r[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m sizes)\n\u001b[1;32m     78\u001b[0m tt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m0\u001b[39m, tt \u001b[39m+\u001b[39m padding \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(tt)))\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# for m in range(len(monitors)):\n",
    "process_video(\n",
    "    f'./recordings/initial/monitor_2_0.mp4', \n",
    "    f'./recordings/compression/monitor_2_0.mp4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcmos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
